# 定义


限流是指在一定时间内，对由于请求过载而可能导致系统崩溃或服务不可用的情况，采取的一种**流量控制手段**。它通过限制请求的速率（Rate）或并发数，拒绝超出限制的请求，从而保护系统资源（CPU、内存、带宽、数据库连接等）。

**核心目的：**

1.  **保护系统（Availability）：** 防止流量突增（如DDoS攻击、秒杀活动）压垮服务器，引发雪崩效应。
2.  **资源分配（Fairness）：** 保证不同用户或服务之间的公平性，防止某个恶意用户占满所有资源。
3.  **成本控制（Cost）：** 限制API调用次数，防止超出付费额度或硬件预算。

---



# 限流的对象与位置

**多维度、多对象一起限流**。

- 入口流量
- 调用者
- 业务操作类型
- 内部资源
- 热点数据
- 后台任务

------

## 0.限流位置

限流算法本质是通用的策略，不是和“前端/后端”绑定的。但真正有约束力的限额一定会落在服务端：

- 对入口流量，一般在网关层用固定窗口、滑动窗口计数或令牌桶控制整体 QPS 和单接口 QPS；
- 在业务服务内部，会对登录、短信、下单等关键接口，以及调用数据库、第三方服务时，再用令牌桶或漏桶做细粒度限流；
- 前端或客户端也会做防抖/节流，但这些都是为了减轻压力和优化体验，不能作为安全防线，因为很容易被绕过。直接大量访问接口。

## 一、对「入口流量」本身限流（网关 / 接口维度）

### **1. 整体入口 QPS**

- 对象：整个站点 / 整个服务的总请求数
- 场景：突发流量、爬虫、DDOS、热点活动
- 位置：API Gateway / Nginx
- 目的：保护整体服务不被瞬间打爆，“宁可少接一点，也别全挂了”

### **2. 单个接口 / 单个 URL**

- 对象：某个具体 API，如 `/login`、`/sendSms`、`/search`
- 场景：
  - 登录接口、短信接口最常单独限流
  - 搜索接口（高耗时、高资源）
- 目的：避免某几个重接口把整个服务拖死

### 实际应用

### 1.  Nginx / OpenResty 自带限流（token bucket）这是整体入口还是单个接口单个url的限流？这是对IP的限流

- 位置：流量入口最前面（SLB → Nginx → 应用）
- 常用指令：
  - `limit_req_zone`：定义限流“规则池”
  - `limit_req`：在哪个 location 上套用规则

示例（按 IP 限流，每秒 10 次请求）：

```nginx
http {
    # 定义限流规则：按客户端 IP 统计，速率 10 req/s   漏桶
    limit_req_zone $binary_remote_addr zone=ip_limit:10m rate=10r/s;

    server {
        listen 80;
        server_name localhost;

        location /api/ {
            # 套用限流规则 zone=ip_limit: 使用前面定义的那个名为 ip_limit 的规则。
            limit_req zone=ip_limit burst=20 nodelay;
            # 如果没有 burst，超过 10r/s 的请求会被直接拒绝（503错误） 有了 burst=20，如果某个 IP 突然在一秒内发来了 30 个请求，前 10 个按正常速率处理，多出来的 20 个请求不会马上报错，而是放入队列（桶）里排队等待处理。

            proxy_pass http://127.0.0.1:8080;
        }
    }
}
```

- `rate=10r/s`：平均每秒允许 10 个

- `burst=20`：允许短时间的突发 20 个排队

- **nodelay**: **关键参数！不延迟处理**。

  - **如果不加 nodelay**：那 20 个排队的请求，会严格按照“每 100ms 处理一个”的速度慢慢执行。用户会感觉网页响应变慢了。
  - **加了 nodelay**：那 20 个在缓冲区里的请求，**只要桶里有空间，就立即处理，不需要排队等待**。
  - **综合效果**：允许瞬间突发 20 个请求。如果你一下子发了 30 个请求：
    - 第 1-21 个（1个正常+20个burst）：**瞬间成功**。
    - 第 22-30 个：**直接报错 503**。
    - *但是*，因为你透支了 20 个 burst 配额，接下来的几秒内，你的请求速率会被严格限制，直到“桶里的水漏完”腾出空间。

- **不带 burst：** 相当于桶容量为0，严格的定速器。

- **带 burst 不带 nodelay：** 标准漏桶，请求排队，延迟高。

- **带 burst + nodelay：** 变种漏桶（类似信用卡机制 你手里没钱，但是你有一张额度为 20 元的信用卡（Burst=20），遇到商品，你可以**先透支刷卡**（瞬间处理，nodelay），但是，刷了卡之后，你的额度就没了。先消费（透支额度），再慢慢还债。透支额度可以看做令牌，功能上与令牌桶等价），既限制了平均速率，又兼顾了突发流量的响应速度。

- Nginx 官方文档定义其为**漏桶算法（Leaky Bucket）**。

  **但是**，Nginx 的实现非常灵活。

  1. 如果不加配置，它是标准的漏桶，主要用于**削峰填谷**，平滑流量。
  2. 一旦配置了 burst 和 nodelay，它的行为特性就变得和**令牌桶（Token Bucket）**几乎一致了：既能限制平均速率，又能允许瞬间的突发流量。

  所以，在实际生产应用中，我们通常把它当作支持突发流量的令牌桶效果来使用。

**这一层挡掉大量脏流量 / 突刺流量**。



### 2. API Gateway + Redis 限流（按接口 / 调用方维度） 可以用redis lua脚本，设计不同的key对不同维度限流，可以对整体入口限流（整体入口都经过某一个key），可以对单个接口单个入口限流

“Redis + Lua”（固定窗口或者滑动窗口） 是目前微服务架构中 API 网关层最主流的分布式限流方案。

比如：

- Spring Cloud Gateway / Kong / Zuul / Envoy 
- 背后一般用 **Redis + Lua** 做分布式限流

常见玩法：

- 维度：`{routeId} + {IP/userId/appId}`
- 算法：固定窗口 / 滑动窗口 / 令牌桶
- 存储：Redis key 计数 + 过期时间

简单 Lua（固定窗口示意）：  可以实现滑动窗口，漏桶和令牌桶

```lua
local key = KEYS[1]         -- 比如 rate:GET:/search:ip:1.2.3.4
local limit = tonumber(ARGV[1])
local current = redis.call("INCR", key)
if current == 1 then
  redis.call("EXPIRE", key, 1) -- 1秒窗口 固定窗口
end
if current > limit then
  return 0   -- 超限
end
return 1      -- 通过
```

**常用这一层做“按接口 + 调用方”的精细限流。**

入口流量通常有**峰值**（比如秒杀、促销），完全不允许突发会非常影响体验；令牌桶可以通过较大 capacity 缓冲短时峰值，同时 rate 控制长期平均负载；滑动窗口计数则用来保证 QPS 不会长期超标。



**网关/入口限流优先令牌桶 → 辅助滑动窗口计数/固定窗口**。





#### Spring Cloud Gateway (SCG)

这是目前 Java 生态最火的网关。

- **底层实现：** 默认使用 RequestRateLimiterGatewayFilterFactory。
- **依赖技术：** **Redis + Lua**。
- **核心算法：** **令牌桶算法 (Token Bucket)**。
- **源码细节：** 它的核心 Lua 脚本在 spring-cloud-gateway-core 包里。它维护了两个 key：
  - request_rate_limiter.{id}.tokens: 当前剩余令牌数。
  - request_rate_limiter.{id}.timestamp: 上次刷新令牌的时间。
- **特点：** 支持 replenishRate (生成速率) 和 burstCapacity (桶容量) 两个参数，完美支持突发流量。

#### Kong

基于 OpenResty (Nginx + Lua) 的高性能网关。

- **底层实现：** 官方插件 Rate Limiting。
- **算法与存储：** 支持多种模式（Policy）：
  - **Local:** 在 Nginx 内存 (shdict) 中使用 **固定窗口** 或 **滑动窗口**。速度最快，但只对单机有效。相当于内置一个redis，省去网络调用，只对单机有效。
  - **Redis:** 使用 Redis 存储计数。通常使用 **固定窗口** 或 **滑动窗口** 算法。
- **特点：** 它的 Redis 模式为了性能，有时会牺牲一点精度（比如异步同步计数），或者使用 Lua 脚本实现精准的滑动窗口。（**“异步同步计数”**（Asynchronous Synchronization / Batching）是为了解决 **“每次请求都查 Redis 导致延迟过高”** 这一痛点而诞生的一种优化策略。简单来说，它的核心思想是：**先把账记在本地（Local），积累到一定程度或一定时间后，再一次性把账单同步给 Redis。**可以通过 **“强一致性（同步）非常精准但是慢”** 和 **“最终一致性（异步）可以积累多少个请求批量发送给redis，或者先批发一批令牌，令牌预取，消耗本地令牌”** 的对比来理解它。）

#### Zuul 1.x (Netflix)  并发限制，也是限流中的一种

比较老旧，基于 Servlet 的阻塞模型。

- **底层实现：** Zuul 1 本身**没有**内置复杂的分布式限流器。
- **通常做法：**
  - **基于 Hystrix：** 利用 Hystrix 的 **线程池隔离** 或 **信号量隔离** 来做并发限制（Concurrency Limit），而不是 RPS 限制。
  - **自定义 Filter：** 开发者通常自己写一个 ZuulFilter，在里面调用 Redis (也就是你上面写的 Lua 脚本) 来实现限流。

#### Envoy

云原生时代的 Sidecar 代理（Service Mesh 标配）。

- **底层实现：** 极其强大，分两层。
- **Local Rate Limit：** 本地（单机）限流，使用 **令牌桶**，C++ 实现，性能极高。
- **Global Rate Limit (RLS)：** 全局分布式限流。Envoy 不直接连 Redis，而是通过 gRPC 调用一个独立的 **Rate Limit Service (RLS)**。
  - 这个 RLS 服务（通常是 Go 或 Java 写）后端再去连 Redis，使用 Redis Lua 实现 **带有权重的滑动窗口** 或 **令牌桶**。



##### 1. 基础维度

- **限制整个 API（保护下游）：**
  - rate:api:/order/create
- **限制某个用户（防恶意刷单）：**
  - rate:user:10086
- **限制某个 IP（防爬虫）：**
  - rate:ip:192.168.1.1

##### 2. 组合维度（精细化控制）

这是最常用的“各种花式限流”：

- **限制某用户调用某接口的频率：**
  - rate:api:/search:user:10086
  - *场景：* VIP 用户每秒可以搜 10 次，普通用户只能搜 2 次。
- **限制某来源 APP 的总调用量：**
  - rate:app_id:client_ios_v2

##### 3. 全局入口限流

- **限制整个网关的总吞吐量：**
  - rate:global
  - *场景：* 后端数据库挂了，网关层通过这个 Key 一键把所有流量降级到 10%。



### 3. 应用内部本地限流（Guava / Resilience4j / Sentinel）

这层在你的 Java 服务里，一般做：

- 单机 QPS 控制
- 特定接口（/login、/sendSms）限流
- 调用下游服务前先限一层，保护下游

常见实现：

- Guava `RateLimiter`（令牌桶）
- Resilience4j `RateLimiter` / `Bulkhead`
- Sentinel（阿里系，网关 + 业务一起配）

典型代码（Guava）：

```java
RateLimiter limiter = RateLimiter.create(100.0); // 每秒 100 次

if (!limiter.tryAcquire()) {
    // 超限，直接拒绝或降级
}
```

------

### 权衡点

对入口流量本身，一般会在网关层做一层限流，再在业务层对关键接口再做一层细粒度限流。
网关层常见的是 Nginx/OpenResty 或 API Gateway 的令牌桶限流，针对整体入口 QPS 和单个 URL 做限额；如果要全局精确控制，会结合 Redis 或专门的 Rate Limit Service 做分布式限流。
 权衡主要集中在：

- 单机 vs 全局：本地限流性能好但不够精确，全局限流精度高但依赖 Redis/RLS；
- 算法上：令牌桶适合入口全局/单接口限流，因为它支持一定突发；需要绝对平滑的场景会考虑漏桶或并发数限流；
- 可用性 vs 风控：限流组件不可用时，是 fail-open 还是 fail-closed，要按业务级别区分。
   通常的组合是：SLB 前面 → 网关做粗粒度入口限流 → 服务内对登录/短信/下单等敏感接口做细粒度限流和降级。





比如 Stripe 和 Uber，对入口限流一般是多层的：

- **网关层：**用令牌桶 / 计数器限流整个服务或账号的全局 QPS（Stripe 默认 100 ops/s，Uber Riders API 500 请求/5秒/应用），并在这一层对每个 endpoint 也配置更紧的限额。[Stripe文档+2Stripe+2](https://docs.stripe.com/rate-limits?utm_source=chatgpt.com)
- **业务层：**有些接口再按 user / ad-account / key 限流，比如 Uber Ads 是按 ad account 维度，而不是 app。[优步开发者](https://developer.uber.com/docs/ads/overview/rate-limiting?utm_source=chatgpt.com)

Netflix、Envoy 系的做法则更多是：

- 每个网关节点做本地令牌桶限流（性能高）
- 再选一些关键场景走全局 Rate Limit Service + Redis 精确控制（精度高）。[kgateway.dev+2GitHub+2](https://kgateway.dev/docs/envoy/main/security/ratelimit/global/?utm_source=chatgpt.com)

这些实现背后要在几个点上做权衡：

- **单机 vs 全局：**本地限流延迟小、可用性好，但全局 QPS 只能近似；全局限流精确但要依赖 Redis/RLS。
- **算法：**入口限流和单 URL 限流多用令牌桶，因为既能控制平均速率又允许短时间突发；对特别“娇贵”的下游服务才会用漏桶或并发数限流来强制平滑。[Stripe+1](https://stripe.com/blog/rate-limiters?utm_source=chatgpt.com)
- **可用性 vs 风控：**限流组件 / Redis 挂了时，是 fail-open（放行保证可用）还是 fail-closed（拒绝保证风控），要根据业务重要性分级（比如支付接口更严格，非关键读接口可以适度放开）。



## 二、对「调用者」限流（谁在用，就对谁限）

### 整体架构先有个图（抽象）

入口一条链路一般是：

> **SLB / LB → API 网关（Nginx / Gateway / Kong / Envoy） → 业务服务**

按“调用者”限流时，大部分公司会这样做：

1. **网关层**：
   - 能拿到 IP、appKey、部分 Header
   - 先做一层粗限流：按 IP、appKey、tenantId、接口 等
2. **业务层**：
   - 拿到 userId / deviceId（登录后才能知道）
   - 对关键操作再做更细粒度限流：登录、短信、发帖、下单等

底层通常是：

- 单机：本地令牌桶（Guava/Resilience4j）
- 集群：**Redis + Lua** 或 专门 Rate Limit 服务（内部封装了 Redis）





这一类是在回答“**按什么维度限流**”。

**1. 按 IP 限流**

- 对象：客户端 IP
- 场景：
  - 防爬虫、防刷接口
  - 防止单个 IP 发起海量请求
- 例子：
  - “单 IP 每分钟最多访问 100 次”

#### 典型场景

- 防爬虫、防刷接口、DDOS 时先挡一层
- “单 IP 每分钟最多访问 100 次”
- 比如前面的nginx网关那个例子



**分布式精细版：网关 / 应用 + Redis**

- key 设计：`rate:ip:{ip}:api:{uri}:minute:{t}`
   比如 `rate:ip:1.2.3.4:/login:2024-12-05T10:01`
- 算法：固定窗口 / 滑动窗口
   例如固定窗口 INCR + EXPIRE：

```lua
-- KEYS[1] = rate:ip:1.2.3.4:/login:2024-12-05T10:01
-- ARGV[1] = limit (如 100)
local c = redis.call('INCR', KEYS[1])
if c == 1 then
  redis.call('EXPIRE', KEYS[1], 60)
end
if c > tonumber(ARGV[1]) then
  return 0  -- 拒绝
end
return 1      -- 通过
```

**2. 按用户 ID / 账号 限流**

- 对象：userId / accountId
- 场景：
  - 防止用户疯狂点赞、评论、发帖子、下单
- 例子：
  - “单用户每天最多发 50 条动态”
  - “单用户每分钟最多下单 10 次”

**位置：业务服务 / 网关（能够解析 token 拿 userId）**

**实现：**

- 用 Redis 做 **计数器**：
  - key：`rate:user:{userId}:action:{op}:unit:{minute/day}`
- 登录 / 下单 / 评论前都先查一次：

伪代码：

```java
String key = "rate:user:" + userId + ":order:minute:" + currentMinute;
Long count = redis.incr(key);
if (count == 1) {
    redis.expire(key, 60);
}
if (count > 10) {
    // 超限，返回错误或降级
}
```

**特点：**

- 更偏“固定窗口计数”，因为业务方喜欢“每分钟 N 次”“每天 N 次”这种说法
- 日限额一般窗口大：expire 设置为一天 / 多天
- 直接在业务代码中进行限额就行了

**3. 按设备 / 终端 限流**

- 对象：deviceId、IMEI、IDFA 等
- 场景：
  - 移动端常见，用来规避同一设备多账号刷行为

**4. 按 appKey / 调用方应用 限流（多租户 / 第三方）**

- 对象：不同接入方，例如合作方 A、B、C，各自有 appKey

- 场景：

  - 对外开放平台（OpenAPI）
  - SaaS 多租户系统

- 例子：

  - “合作方A每秒 500 QPS，合作方B 每秒 100 QPS”

- **目标：**

  - 按 appKey、租户、公司配不同的调用配额：
    - 比如：免费版 1000 QPS，付费版 5000 QPS。
  - 要全局精确计费、控制成本。

  **常用方案：全局令牌桶 / 计数器 + Redis**

  - 规则放在配额中心 / 配置中心；
  - 网关层每次根据 appKey 做 Redis 限流：
    - 固定窗口 / 滑动窗口计数 / 令牌桶都可能用；
  - 为简单可控，一般会选择：
    - **固定窗口 + 令牌桶** 的组合。

  **为什么适配：**

  - 需要对 QPS 和调用总量都有可验证记录（计费 / SLA 支撑）；
  - 令牌桶可以用来保证平均速率，固定窗口计数保证“不超单元窗口配额”。

  > 总结：**租户配额 / appKey 限流 → 令牌桶 + 计数器，后端 Redis 做全局配额管理**。消息推送可以用这个限流策略，不同业务方有各自的配额，令牌桶计数器限额。后端Redis来做所有业务方的全局配额管理。

**5. 按租户 / 公司 ID 限流**

- 对象：tenantId / orgId
- 场景：企业 SaaS、公司级配额
- 例子：
  - “某公司每天最多导入 1 万条数据”

------

## 三、对「业务操作类型」限流（做什么，就对什么限）

同一个接口中也会对**具体动作**限流：

**1. 登录 / 注册** 验证码 敏感操作防刷

- 目标：
  - 防止暴力破解密码
  - 防止恶意注册
- 按 IP / userId / deviceId 做**频次控制**：
  - “同手机号 60 秒最多发 1 条短信，5 分钟最多 5 条”
  - “同账号 1 分钟最多登录失败 5 次”
  - “同 IP/账号 5 分钟最多登录失败 5 次”
  - “同手机号 1 小时最多注册 3 次”
- 需要按“最近一段时间内的次数”精细控制，且数据量一般不大。

**常用方案：固定窗口 + 小粒度滑动窗口（日志 / 计数）**

- 实际实现非常多是**固定窗口**：
   Redis key：`sms:{mobile}:minute:{t}` + `INCR + EXPIRE`；
- 对于更严格的（比如防暴力破解）会用：
  - 短时间内（5分钟）频率过高则封禁更久；
  - 实现上可以用**多个窗口叠加**，或者滑动窗口计数。

**为什么适配：**

- 登录、短信场景 QPS 不如核心查询那样大，用简单计数 + 多窗口组合足够；
- 对“临界翻倍”可以接受甚至还有更严格的封禁规则兜底；
- 内存不希望为每个请求存时间戳（滑动日志太重），滑动计数/固定窗口就够用。

> 总结：**低频但敏感操作 → 多维度固定窗口计数 + 有时配合滑动窗口**。

**2. 短信 / 邮件发送**

- 目标：
  - 防止短信轰炸 / 成本爆炸
- 常见规则：
  - “同手机号 60 秒只能发 1 条”
  - “同手机号每天最多发 5 条验证码”

**3. 支付 / 下单 / 退款**

- 目标：
  - 防作弊、防并发下单、防接口被打挂
- 例子：
  - “同用户 1 秒内只能下单一次”
  - “同订单号退款接口每分钟最多调用 1 次”

**4. 评论 / 点赞 / 关注 / 收藏**

- 目标：
  - 防刷量、防灌水、防机器人
- 例子：
  - “同用户每分钟最多发 10 条评论”
  - “关注操作做冷却时间：5 秒一次”

**5. 搜索 / 查询**

- 目标：
  - 搜索是高耗时/高资源，容易被爬虫打爆
- 例子：
  - “同 IP 每秒最多搜索 5 次”
  - “同用户 1 分钟最多搜索 30 次”

**6. 上传 / 下载**

- 对象：
  - 文件上传次数、带宽使用量
- 场景：
  - OSS / CDN / 像快手这种视频上传接口
- 规则：
  - “同用户每天最多上传 N 个视频”
  - “单连接带宽限流，防止占满出口”

------

## 四、对「内部资源」限流（保护后端依赖）

这一类回答的是：**不是只保护接口，还要保护后面的依赖资源**。

**1. 数据库 QPS / 连接数**

- 对象：MySQL / Redis / ES 等
- 场景：
  - 高峰期防止数据库被击穿
- 手段：
  - 业务层限流
  - 连接池限制最大连接数
  - 针对某些“重查询”接口单独限流

**2. 下游 HTTP / RPC 服务**

- 对象：调用其他微服务、三方支付接口、推荐服务等
- 场景：
  - 防止对方服务被你干趴
  - 自己也要防止越来越多线程堆在那里等超时
- 常见做法：
  - 针对每个下游设置独立限流 + 超时 + 熔断 + 降级

**3. 消息队列 / 任务消费速度**

- 对象：Kafka / RocketMQ consumer 端消费速率

- 场景：

  - 防止消费太快，压垮下游 DB 或接口

- 做法：

  - 控制消费线程数 / 批量大小
  - 在消费方做“限速消费”

- **目标：**

  - 保护数据库 / 搜索引擎 / 三方 API，不被瞬间大量写/查压垮；
  - 更注重**整体稳定性**，允许拒绝一部分请求。

  **常用方案：漏桶 + 并发数限流 / 线程池**

  - 比如：
    - 消费 MQ 的时候对写 DB 的速率用**漏桶限流**（匀速写入）；
    - 或者直接用一个有界队列 + 固定消费线程，相当于漏桶 + 排队；
  - 加上 **并发数限制**：同时最多有 N 个请求在执行慢查询。

  **为什么适配：**

  - 这里比起用户体验，**更重要的是不能把 DB 打爆**；
  - 漏桶的匀速特性非常契合“慢资源”保护；
  - 即使前端突然来一波高峰，由于队列/桶满就 throttle/拒绝/延迟，不会瞬间冲垮下游。

  > 总结：**保护弱依赖 → 漏桶 / 并发数限流 是首选**。

**4. 线程池 / 本机资源**

- 对象：线程池队列长度、CPU/内存
- 场景：
  - 防止短时间创建过多任务，队列爆掉/CPU 100%
- 做法：
  - 线程池参数 + 拒绝策略 + 限流（拒绝新请求）

------

## 五、对「热点数据 / 热点 key」限流

**1. 热点商品 / 热点视频 / 热门话题**

- 对象：某个热门资源的访问、点赞、评论等
- 场景：
  - 秒杀、抢券、大 V 视频、爆款短视频
- 做法：
  - 对这个资源 ID 维度做限流或限并发，例如：
    - “同一商品详情接口总 QPS 不超过 1w”
    - “同一视频的点赞请求做排队/限流”

**2. Redis 热点 key**

- 对象：单 key QPS 太高，导致 CPU/带宽集中在一个key上
- 做法：
  - 本地缓存 + 多级缓存
  - 针对某个 key 做访问频率限制

------

## 六、对「后台任务 / 批处理」限流

**1. 大批量导入 / 导出任务**

- 场景：
  - 后台管理系统：导入用户、导出数据报表
- 限流点：
  - 限制：每天可触发几次、每次最大数据量
  - 限制：任务并发数，后台 worker 并发执行数量

**2. 定时任务 / 扫描任务**

- 场景：
  - 像你之前的定时任务系统，扫描到期任务、批量推送任务
- 限流点：
  - 扫描频率（例如 Redis + MySQL）
  - 单次触发任务数
  - 下发速率（防止一次触发海量请求打挂业务）

------











# 五大主流限流算法

我们将之前讨论的“滑动窗口”拆分为**滑动窗口日志**和**滑动窗口计数**，正好凑齐五大主流限流算法。

以下是这五种算法的**定义**以及**核心 Java 代码实现**（为了便于理解原理，代码为简化版的线程安全实现，生产环境建议使用 Guava、Sentinel 或 Redis Lua）。

---

### 1. 固定窗口计数器 (Fixed Window Counter)

**定义：**
将时间划分为固定的窗口（如 1 秒）。在当前窗口内，每来一个请求计数器加 1。如果计数器超过阈值，拒绝请求。时间到达下一个窗口时，计数器重置。

**特点：** 实现最简单，但存在“临界突变”问题（两个窗口交界处流量可能翻倍），只能保证“每个时间片不超过 N”，不能保证“任意连续 1 秒不超过 N”。

**使用考量：**对限流精度要求没那么高，只是要一个“保护阈值”的场景。你愿意用**简单换精度**，并且可以接受窗口边界偶尔翻倍。

**Java 代码实现：**
```java
import java.util.concurrent.atomic.AtomicInteger;

public class FixedWindowRateLimiter {
    // 阈值：每秒限制 10 个请求
    private final int limit = 10;
    // 窗口大小：1000 毫秒
    private final long windowSize = 1000;
    
    // 计数器
    private AtomicInteger count = new AtomicInteger(0);
    // 当前窗口的开始时间
    private long windowStart = System.currentTimeMillis();

    public synchronized boolean tryAcquire() {
        long currentTime = System.currentTimeMillis();
        
        // 检查是否进入了新的窗口
        if (currentTime - windowStart > windowSize) {
            count.set(0); // 重置计数器
            windowStart = currentTime; // 重置窗口时间
        }
        
        // 检查是否超过阈值
        if (count.incrementAndGet() <= limit) {
            return true; // 允许通过
        }
        return false; // 拒绝请求
    }
}
```

---

### 2. 滑动窗口日志 (Sliding Window Log)

**定义：**
记录**每一个**请求的时间戳。当新请求到来时，统计当前时间往前推一个窗口长度（如过去 1 秒）内的请求总数。如果总数小于阈值，则允许通过，并记录当前请求时间。

**特点：** 精度非常高（100%），但随着 QPS 升高，内存消耗呈线性增长，计算成本高。

**使用考量：**流量不大，但对行为约束非常严格的业务：比如：修改重要配置、关键风控操作、管理后台某些操作。不适合做通用网关限流（量大时太贵）。

**Java 代码实现：**

```java
import java.util.ArrayDeque;
import java.util.Deque;

public class SlidingWindowLogRateLimiter {
    private final int limit = 10;
    private final long windowSize = 1000;

    // 使用更高性能的 ArrayDeque
    private final Deque<Long> timestamps = new ArrayDeque<>();

    public synchronized boolean tryAcquire() {
        long now = System.currentTimeMillis();

        // 1. 移除过期的时间戳
        while (!timestamps.isEmpty() && (now - timestamps.peekFirst() > windowSize)) {
            timestamps.pollFirst();  // 等价于 removeFirst，但不会抛异常
        }

        // 2. 判断当前窗口数量
        if (timestamps.size() < limit) {
            timestamps.offerLast(now); // 等价 addLast
            return true;
        }

        return false;
    }
}

```

---

### 3. 滑动窗口计数 (Sliding Window Counter / Window Rolling)

**定义：**
将大窗口（如 1 秒）切分成多个小格子（如 10 个 100ms 的格子）。每个格子单独计数。随着时间流动，窗口向右移动，移除最左边的格子，加入右边的新格子。统计值为当前窗口内所有格子的计数之和。

**特点：** 解决了固定窗口的临界问题，内存占用比“日志法”小得多，工程实践中最常用的滑动窗口实现。Sentinel 和 Hystrix 均采用此法。

**使用考量：**网关、服务限流组件内部常用：Sentinel、Hystrix、Envoy 等内部都用类似方案。对性能有要求、又需要比固定窗口更精细的控制：大量接口的 QPS 控制。微服务调用降级

**Java 代码实现（简化版）：**

```java
import java.util.concurrent.atomic.AtomicInteger;

public class SlidingWindowCounterRateLimiter {
    private final int limit = 10;
    private final int windowSize = 1000;
    private final int bucketCount = 10; 
    private final int bucketSize = windowSize / bucketCount;

    private final AtomicInteger[] buckets = new AtomicInteger[bucketCount];
    private volatile long lastResetTime = System.currentTimeMillis();

    public SlidingWindowCounterRateLimiter() {
        for (int i = 0; i < bucketCount; i++) {
            buckets[i] = new AtomicInteger(0);
        }
    }

    public synchronized boolean tryAcquire() {
        long now = System.currentTimeMillis();
        int index = (int) ((now / bucketSize) % bucketCount);

        // 如果离上次重置时间超过一个窗口大小，就清空所有 bucket
        if (now - lastResetTime >= windowSize) {
            resetAll();
        }

        // 当前 bucket 计数 + 其他 bucket 总和
        int total = 0;
        for (AtomicInteger bucket : buckets) {
            total += bucket.get();
        }

        if (total < limit) {
            buckets[index].incrementAndGet();
            lastResetTime = now;
            return true;
        }
        return false;
    }

    private void resetAll() {
        for (AtomicInteger bucket : buckets) {
            bucket.set(0);
        }
    }
}

```

---

### 4. 漏桶算法 (Leaky Bucket)

**定义：**
模拟一个底部有孔的桶。请求像水一样流入桶中，桶以**恒定速率**漏水（处理请求）。如果桶满了，新进入的水（请求）会被丢弃。

**特点：** **强制削峰填谷**，输出速率是恒定的。适合保护处理能力有限的下游系统（如数据库）。对**突发流量不友好**：桶满就直接 drop，请求不会因为你之前很空闲就自动“积累配额”。如果要排队（不丢），就需要额外队列 + 消费线程，编程模型更复杂（类似 MQ）。

**使用考量：**适合场景：写数据库、写 ES、发送邮件/短信等“慢资源”场景。后台任务消费 / 批处理。不太适合对用户体验敏感的外部接口入口（除非你宁可拒绝也不能打挂）。

**Java 代码实现（数学计算法，非物理队列）：**
*注：物理队列法需要后台线程消费，比较重；通常使用如下的数学法（Lazy Leaking）实现。*

```java
public class LeakyBucketRateLimiter {
    private double capacity = 10;    // 桶的容量
    private double rate = 1;         // 水流出的速度 (每毫秒处理多少个请求，这里假设 1req/ms)
    private double water = 0;        // 当前水量
    private long lastLeakTime = System.currentTimeMillis();

    public synchronized boolean tryAcquire() {
        long now = System.currentTimeMillis();
        
        // 1. 计算这段时间流出了多少水
        // (now - lastLeakTime) * rate
        double leaked = (now - lastLeakTime) * rate; // 注意：这里速率单位要匹配
        
        // 2. 更新水量（不能小于0）
        if (leaked > 0) {
            water = Math.max(0, water - leaked);
            lastLeakTime = now;
        }
        
        // 3. 尝试加水（处理请求）
        if (water + 1 <= capacity) {
            water++;
            return true;
        }
        return false;
    }
}
```

---

### 5. 令牌桶算法 (Token Bucket)

**定义：**
系统以**恒定速率**向桶中放入令牌（平均速率）。桶有最大容量，满了就不放了。请求到来时，必须拿到令牌才能被处理。如果桶内有存货，可以瞬间处理大量请求（突发流量）。

**特点：** **允许突发流量**，是最常用的限流算法。非常适合作为 **API 限流首选算法**。实现简单，典型实现：Guava `RateLimiter`、Spring Cloud Gateway `RedisRateLimiter` 等。但输出不如漏桶那么平滑，可能会出现短时高峰（但在可控范围内）。`rate` / `capacity` 需要调参。

**使用考量：**通用接口限流、网关入口限流、下游服务保护：希望“平时有节制 + 短期高峰也能扛一扛”。

**Java 代码实现（核心逻辑）：**
*业界标准：Google Guava 的 RateLimiter*

```java
public class TokenBucketRateLimiter {
    private double capacity = 10;      // 桶容量
    private double rate = 1;           // 产生令牌的速率 (每秒 N 个)
    private double tokens = 0;         // 当前令牌数量
    private long lastRefillTime = System.currentTimeMillis();

    public synchronized boolean tryAcquire() {
        long now = System.currentTimeMillis();
        
        // 1. 计算这段时间生成了多少令牌
        // 假设 rate 是每秒生成多少个，时间差要转换为秒
        double generated = (now - lastRefillTime) / 1000.0 * rate;
        
        // 2. 放入令牌（不能超过桶容量）
        if (generated > 0) {
            tokens = Math.min(capacity, tokens + generated);
            lastRefillTime = now;
        }
        
        // 3. 拿令牌
        if (tokens >= 1) {
            tokens--;
            return true;
        }
        return false;
    }
}
```

**生产环境使用推荐（Guava）：**
```java
// 每秒放 5 个令牌
RateLimiter limiter = RateLimiter.create(5.0); 

if (limiter.tryAcquire()) {
    // 处理请求
} else {
    // 被限流
}
```

---

### 总结选择指南

1.  **简单粗暴、允许波动：** 固定窗口。
2.  **业务逻辑限流、低频高精：** 滑动窗口日志。
3.  **高并发网关、精准度要求高：** 滑动窗口计数（Sentinel）。
4.  **需要绝对平滑、保护弱依赖：** 漏桶。
5.  **通用接口限流、允许突发：** 令牌桶（Guava, Spring Cloud Gateway）。







# 选型顺序

**先问：精度需求？还是简单可靠优先？**

- 只要防过载、不追求完美 → 固定窗口 或 令牌桶。
- 必须精确到“任意时间段” → 滑动窗口（日志/计数）。

**再问：业务允许突发吗？希望平滑还是允许冲一冲？**

- 要平滑输出，保护弱下游 → 漏桶 + 并发限流。
- 希望支持短时高峰 → 令牌桶。

**QPS/规模如何？**

- QPS 不高，接口少 → 简单实现：固定窗口、滑动日志也 OK。
- 高并发、需要通用组件 → 滑动窗口计数 / 令牌桶。

**单机还是集群？**

- 单机：直接用 Guava RateLimiter / 内存滑动窗口计数。
- 集群：用 Redis + Lua 或 Rate Limit Service，算法可以是固定窗口 / 令牌桶 / 滑动窗口计数。



全局分布式限流。Envoy 不直接连 Redis，而是通过 gRPC 调用一个独立的 **Rate Limit Service (RLS)**。

- 这个 RLS 服务（通常是 Go 或 Java 写）后端再去连 Redis，使用 Redis Lua 实现 **带有权重的滑动窗口** 或 **令牌桶**。